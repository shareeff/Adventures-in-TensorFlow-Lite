{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Authorize `wandb`\n",
    "HAS_WANDB_ACCOUNT = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
    "import wandb\n",
    "if not HAS_WANDB_ACCOUNT:\n",
    "    wandb.login(anonymous='allow')\n",
    "else:\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title training parameters\n",
    "keras = tf.keras\n",
    "l = keras.layers\n",
    "\n",
    "batch_size = 128 #@param {type:\"integer\"}\n",
    "num_classes = 10 #@param {type:\"integer\"}\n",
    "epochs = 12 #@param {type:\"integer\"}\n",
    "# input image dimensions\n",
    "img_rows = 28 #@param {type:\"integer\"}\n",
    "img_cols = 28 #@param {type:\"integer\"}\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "save_path = \"./saved/base_mnist.h5\" #@param {type:\"string\"}\n",
    "save_path_pruning_model =  \"./saved/pruning_mnist.h5\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(save_path_pruning_model).parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset.\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Add a channel dimension.\n",
    "train_images = train_images.reshape(-1, img_rows, img_cols, 1)\n",
    "test_images = test_images.reshape(-1, img_rows, img_cols, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "    inp = tf.keras.Input(shape=input_shape)\n",
    "    x = l.Conv2D(32, 5, padding='same', activation='relu')(inp)\n",
    "    x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)\n",
    "    x = l.BatchNormalization()(x)\n",
    "    x = l.Conv2D(64, 5, padding='same', activation='relu')(x)\n",
    "    x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)\n",
    "    x = l.Flatten()(x)\n",
    "    x = l.Dense(1024, activation='relu')(x)\n",
    "    x = l.Dropout(0.4)(x)\n",
    "    out = l.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return tf.keras.models.Model([inp], [out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              3212288   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 3,274,762\n",
      "Trainable params: 3,274,698\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ilab/tensorflow_pruning\" target=\"_blank\">https://app.wandb.ai/ilab/tensorflow_pruning</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ilab/tensorflow_pruning/runs/vanilla-training-cnn\" target=\"_blank\">https://app.wandb.ai/ilab/tensorflow_pruning/runs/vanilla-training-cnn</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Train a simple CNN without any pruning\n",
    "wandb_run_id = \"vanilla-training-cnn\" #@param {type:\"string\"}\n",
    "if HAS_WANDB_ACCOUNT:\n",
    "        wandb.init(entity='ilab', project='tensorflow_pruning', id=wandb_run_id)\n",
    "else:\n",
    "    wandb.init(id=wandb_run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 28, 28, 1)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(dataset))\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for x, y in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model([x])\n",
    "            loss_value = loss(y, y_pred)\n",
    "            wandb.log({'epoch': epoch, 'loss': loss_value})\n",
    "            gradients = tape.gradient(loss_value, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 28, 28, 1)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(test_dataset))\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = tf.keras.metrics.Accuracy()\n",
    "def evaluate_model(eval_model):\n",
    "    for x, y in test_dataset:\n",
    "        logits = eval_model([x])\n",
    "        prediction = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        test_accuracy(prediction, y)\n",
    "    \n",
    "    print(\"Test set accuracy: {:.3%}\".format(test_accuracy.result()))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 99.150%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ilab/tensorflow_pruning\" target=\"_blank\">https://app.wandb.ai/ilab/tensorflow_pruning</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ilab/tensorflow_pruning/runs/pruning-trained-net\" target=\"_blank\">https://app.wandb.ai/ilab/tensorflow_pruning/runs/pruning-trained-net</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Take a trained network, prune it with more training\n",
    "target_sparsity = 0.5 #@param {type:\"number\"}\n",
    "begin_step = 0 #@param {type:\"integer\"}\n",
    "end_step =  -1 #@param {type:\"integer\"}\n",
    "frequency = 1 #@param {type:\"integer\"}\n",
    "epochs = 4 #@param {type:\"integer\"}\n",
    "wandb_run_id = \"pruning-trained-net\" #@param {type:\"string\"}\n",
    "\n",
    "if HAS_WANDB_ACCOUNT:\n",
    "        wandb.init(entity='ilab', project='tensorflow_pruning', id=wandb_run_id)\n",
    "else:\n",
    "    wandb.init(id=wandb_run_id)\n",
    "    \n",
    "# Define pruning schedule\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(\n",
    "          target_sparsity=target_sparsity,\n",
    "          begin_step=begin_step,\n",
    "          end_step=end_step,\n",
    "          frequency=frequency\n",
    "      )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:From /media/shareef/MLDev/Python_Project/2020Projects/GooglePlay/Venv/tf2.2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:193: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(save_path)\n",
    "loaded_model_weights = loaded_model.get_weights()\n",
    "\n",
    "base_model = build_model(input_shape)\n",
    "base_model.set_weights(loaded_model_weights)\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning\n",
    "unused_arg = -1\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "model.optimizer = optimizer\n",
    "step_callback = tfmot.sparsity.keras.UpdatePruningStep()\n",
    "step_callback.set_model(model)\n",
    "log_callback = tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir) # Log sparsity and other metrics in Tensorboard.\n",
    "log_callback.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = tf.keras.optimizers.Adam()\n",
    "step_callback.on_train_begin() # run pruning callback\n",
    "for epoch in range(epochs):\n",
    "    log_callback.on_epoch_begin(epoch=unused_arg) # run pruning callback\n",
    "    for x, y in dataset:\n",
    "        step_callback.on_train_batch_begin(batch=unused_arg) # run pruning callback\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model_for_pruning([x])\n",
    "            loss_value = loss(y, y_pred)\n",
    "            wandb.log({'epoch': epoch, 'loss': loss_value})\n",
    "            gradients = tape.gradient(loss_value, model_for_pruning.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model_for_pruning.trainable_variables))\n",
    "    step_callback.on_epoch_end(batch=unused_arg) # run pruning callback\n",
    "        \n",
    "\n",
    "model_for_pruning.save(save_path_pruning_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 98.925%\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_for_pruning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c58bed9ba4c8091c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c58bed9ba4c8091c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#docs_infra: no_execute\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={log_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /tmp/tmpj84dws08.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Lite model saved to:  /tmp/tmp9pc4o_q3.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quantized_and_pruned_tflite_file, 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "\n",
    "print(\"TF Lite model saved to: \",quantized_and_pruned_tflite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tflite_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on ever y image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for i, test_image in enumerate(test_images):\n",
    "        if i % 1000 == 0:\n",
    "            print('Evaluated on {n} results so far.'.format(n=i))\n",
    "        # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "        # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "        # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "    print('\\n')\n",
    "    # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    prediction_digits = np.array(prediction_digits)\n",
    "    accuracy = (prediction_digits == test_labels).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on 0 results so far.\n",
      "Evaluated on 1000 results so far.\n",
      "Evaluated on 2000 results so far.\n",
      "Evaluated on 3000 results so far.\n",
      "Evaluated on 4000 results so far.\n",
      "Evaluated on 5000 results so far.\n",
      "Evaluated on 6000 results so far.\n",
      "Evaluated on 7000 results so far.\n",
      "Evaluated on 8000 results so far.\n",
      "Evaluated on 9000 results so far.\n",
      "\n",
      "\n",
      "Pruned and quantized TFLite test_accuracy: 0.9871\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantized_and_pruned_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "test_accuracy = evaluate_tflite_model(interpreter)\n",
    "\n",
    "print('Pruned and quantized TFLite test_accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
